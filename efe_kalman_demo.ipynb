{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/biaslab/repos/kalman_filters/Project.toml`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "posterior (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg;Pkg.activate(\".\");Pkg.instantiate()\n",
    "using Distributions, Zygote, PDMats\n",
    "include(\"utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of Expected Free Energy\n",
    "This notebook is a demo of EFE in a Kalman filter-like model. Also currently a showcase of bad writing, placeholders and tests of how to write a proper demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting point is the original 2015 EFE paper. In it Friston defines EFE as\n",
    "\\begin{align}\n",
    "EFE = \\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{p(o,s|\\pi)} \\mathrm{d}o \\mathrm{d}s\n",
    "\\end{align}\n",
    "However taking a closer look at the implementation, we notice a few details. The model in question is the, by now, canonical T-maze experiment. It is defined on a discrete state spaces in terms of 5 matrices, 4 of which are relevant for this demo\n",
    "\\begin{align}\n",
    "p(o_t|s_t) = A\\\\\n",
    "p(s_t | s_{t-1}, u_t) = B(u_t)\\\\\n",
    "p(o_t|m) = C\\\\\n",
    "p(s_0 | m) = D\n",
    "\\end{align}\n",
    "Here $A$ encodes the likelihood models, $B(u_t)$ a state transition that depends on action $u_t$ and $D$ a belief over the initial state. All of these can be recovered from the canonical EFE derivation in Appendix A. However the matrix $C$ does not feature in the derivation in the appendix, so it deserves a special mention. It denotes a prior over future outcomes in terms of their __utility__.\\\n",
    "Quote \"The priors over future outcomes specify their utility $C(o_t|m) = p(o_t|m) = ln C_t$\". This matrix specifies a cost associated with each state and is the driving term behind goal directed behaviour. If we incorporate $p(o|m)$ into the derivation of EFE we end up with an additional term. This term is not unknown in AI literature and has for instance been seen in \\cite{thijs} as a \"goal prior\". We write\n",
    "\\begin{align}\n",
    "EFE &= \\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{p(o,s|\\pi)p(o|m)} \\mathrm{d}o \\mathrm{d}s\\\\\n",
    "&\\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{\\bar{p}(o,s|\\pi)} \\mathrm{d}o \\mathrm{d}s\\\\\n",
    "&\\bar{p}(o,s | \\pi) = \\frac{1}{Z}p(o,s |\\pi)p(o|m)\n",
    "\\end{align}\n",
    "\\\n",
    "Where in the last line we utilize the same definition as \\cite{generalised FE 2019}. Decomposing this EFE we find\n",
    "\\\n",
    "\\begin{align}\n",
    "EFE &= \\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{\\bar{p}(o,s|\\pi)} \\mathrm{d}o \\mathrm{d}s\\\\\n",
    "&=\\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{p(o,s|\\pi)} - \\log p(o|m)\\mathrm{d}o \\mathrm{d}s\\\\\n",
    "&=\\iint \\widetilde{q}(o,s|\\pi) \\log \\frac{q(s|\\pi)}{p(o,s|\\pi)} \\mathrm{d}o \\mathrm{d}s - \\iint \\widetilde{q}(o,s|\\pi) \\log p(o|m)\\mathrm{d}o \\mathrm{d}s\\\\\n",
    "&= H[\\widetilde{q}(o,s|\\pi)||p(o,s|\\pi)] -H[q(s | \\pi)] - \\mathbf{E}_{\\widetilde{q}(o,s|\\pi)} [C_t]\n",
    "\\end{align}\n",
    "\\\n",
    "where we recognise that EFE - with all terms used in the experiments included - decompose into an entropy term, a crossentropy and an expected utility or reward term relying on an arbitrary cost function. This cost is usually interpreted as a preference over future outcomes or a goal prior.\\\n",
    "The next step is to examine the defition of $\\widetilde{q}(o,s|\\pi)$. This is given in Appendix A of \\cite{efe paper} as\n",
    "\\begin{align}\n",
    "\\widetilde{q}(o,s|\\pi) = p(o|s)q(s|\\pi)\n",
    "\\end{align}\n",
    "However upon examination of the simulations this turns out to denote that the same matrix $A$ is used as the likelihood for both generative and recognition densities. We are therefore justified in writing\n",
    "\\begin{align}\n",
    "\\widetilde{q}(o,s|\\pi) = p(o|s)q(s|\\pi) = q(o|s)q(s|\\pi) = q(o,s|\\pi)\n",
    "\\end{align}\n",
    "without violating the definition of EFE. The final expression then becomes\n",
    "\\begin{align}\n",
    "EFE = H[q(o,s|\\pi)||p(o,s|\\pi)] -H[q(s | \\pi)] - \\mathbf{E}_{\\widetilde{q}(o,s|\\pi)} \\log [C_t]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Entropy\n",
    "Conditional entropy can be defined as \n",
    "\\begin{align}\n",
    "H[p(x|y)] = \\sum_y p(y) \\sum_x p(x|y) \\log p(x|y) = \\sum_{x,y} p(x,y) \\log p(x|y)\n",
    "\\end{align}\n",
    "Multiplying and dividing by $p(y)$\n",
    "\\begin{align}\n",
    "H[p(x|y)] = \\sum_{x,y} p(x,y) \\log \\frac{p(y)}{p(x,y)}\n",
    "\\end{align}\n",
    "If we assume the optimization of EFE was successful - and $p=q$ (which is not unreasonable given that there are no data constraints) - we can substitute the relevant terms into the definition of conditional entropy and write\n",
    "\\begin{align}\n",
    "H[p(x|y)] = \\sum_{x,y} q(x,y) \\log \\frac{q(y)}{p(x,y)} = \\sum_{o,s} q(o,s|\\pi) \\log \\frac{q(s|\\pi)}{p(o,s|\\pi)} = H[p(o|s)]\n",
    "\\end{align}\n",
    "Substituting back into the full expression we find that EFE can be interpreted as optimizing an expected cost $\\mathbf{E}_{\\widetilde{q}(o,s|\\pi)} [C_t]$ and a term that approaches the conditional entropy of observations $o$ given states $s$. The expected cost drives goal directed behaviour and regularization by an approximate conditional entropy drives exploration. It is also in agreement with the equations used to simulate the canonical T-maze experiment originally presented in \\cite{friston 2015} Now we turn towards implementing an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "We will simulate a linear Gaussian dynamical system with additive control. This is very similar in structure to a Kalman filter with a few keyt differences. First of all, EFE is only applicable for future timepoints. This means there are no data points available for the model. In the absence of data we can rely on the predictive distribution of our generative model to provide a prior over future trajectories.\\\n",
    "Initially the posterior predictive distribution will be identical to the recognition density $q$ since there are no data constraints. Treating $q(\\pi_t)$ as a parameter vector we can then optimize EFE to trade off between expected cost and approximate conditional entropy. We assume $p(\\pi_t) = 0$ for all $t$ and define initial state\n",
    "\\begin{align}\n",
    "p(s_0) = q(s_0) = \\mathcal{N}([1,1],I)\n",
    "\\end{align}\n",
    "with transition matrix A and process noise Q\n",
    "\\begin{align}\n",
    "A = I \\\\\n",
    "Q = I * 0.1\n",
    "\\end{align}\n",
    "emission matrix H and observation noise R\n",
    "\\begin{align}\n",
    "H = R = I\n",
    "\\end{align}\n",
    "and goal prior $p(o|m)$\n",
    "\\begin{align}\n",
    "\\mathcal{N}([2,2],I)\n",
    "\\end{align}\n",
    "This choice of goal prior a feature of EFE by making the expected cost a crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_EFE (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate cross entropy properly\n",
    "function cross_entropy_gaussians(p,q)\n",
    "    # Calculates cross entropy of 2 MvNormals\n",
    "    kl_mvgaussians(p,q) + entropy(q)\n",
    "end\n",
    "\n",
    "function kl_mvgaussians(q,p)\n",
    "    if size(p) != size(q)\n",
    "        println(\"Dimensionality mismatch!\")\n",
    "    else\n",
    "\n",
    "    Σ_q = Matrix(q.Σ)\n",
    "    Σ_p = Matrix(p.Σ)\n",
    "    # Fix division by 0 and make sure dim of n is correct. Also having to use \"Matrix()\" is bad.\n",
    "    return 0.5* (\n",
    "\t  log(det(Σ_q) / det(Σ_p)) -\n",
    "\t  size(p)[1] +\n",
    "\t  tr(inv(Σ_q)* Σ_p) +\n",
    "      transpose(q.μ - p.μ) * inv(Σ_q) * (q.μ - p.μ)\n",
    "        )\n",
    "    end\n",
    "end\n",
    "\n",
    "# Computes EFE for known transition and emission matrices, up to a time horizon T\n",
    "function compute_EFE(p_s_0,q_s_0,p_o_given_m,π_t,A,Q,H,R,T)\n",
    "    # p_s_0 = Prior over initial state\n",
    "    # q_s_0 = initial recognition dist over initial state\n",
    "    # p_o_given_m = p(o|m), goal prior\n",
    "    # π_t = q(π), vector of actions. Same dimensionality as states\n",
    "    # A = Transition matrix\n",
    "    # Q = Process noise\n",
    "    # H = Emission matrix\n",
    "    # R = Emission noise\n",
    " \n",
    "    # Start loss at 0\n",
    "    loss = 0\n",
    "    \n",
    "    for t ∈ 1:T\n",
    "        # Compute next states q(s_t|s_{t-1}, π_t). Known dynamics A, so only param is action π_t\n",
    "        q_s_t = MvNormal(A*q_s_0.μ + π_t[t],A*q_s_0.Σ*transpose(A) + Q)\n",
    "        \n",
    "        # Compute prior p(s_t | s_{t-1}). p(π_t) = 0, ie we don't assume any action apriori\n",
    "        p_s_t = MvNormal(A*p_s_0.μ ,A*p_s_0.Σ*transpose(A) + Q)\n",
    "\n",
    "        # Compute joint q(o,s | π_t)\n",
    "        q_os_t = MvNormal([q_s_t.μ;H*q_s_t.μ],\n",
    "                  [q_s_t.Σ q_s_t.Σ*transpose(H) ;\n",
    "                   H*q_s_t.Σ H*q_s_t.Σ*transpose(H) + R])\n",
    "\n",
    "        # Compute joint p(o,s|s_{t-1})\n",
    "        p_os_t = MvNormal([p_s_t.μ;H*p_s_t.μ],\n",
    "                  [p_s_t.Σ p_s_t.Σ*transpose(H) ;\n",
    "                   H*p_s_t.Σ H*p_s_t.Σ*transpose(H) + R])\n",
    "\n",
    "        # Compute marginal q(o_t)\n",
    "        q_o = MvNormal(H*q_s_t.μ,H*q_s_t.Σ*transpose(H) + R)\n",
    "\n",
    "        # Evaluate loss as H[q(o,s|pi) || p(o,s|s_{t-1})] - H[q(s_t)] + H[p(o) || p(o|m)]\n",
    "        loss += cross_entropy_gaussians(p_os_t,q_os_t) - entropy(q_s_t) + cross_entropy_gaussians(q_o,p_o_given_m)\n",
    "        \n",
    "        # Print terms\n",
    "        println(\"Approximate conditional entropy: \",cross_entropy_gaussians(p_os_t,q_os_t) - entropy(q_s_t))\n",
    "        println(\"Instrumental value: \", cross_entropy_gaussians(q_o,p_o_given_m))\n",
    "        \n",
    "        # Update distributions for next timestep\n",
    "        q_s_0 = q_s_t\n",
    "        p_s_0 = p_s_t \n",
    "    end\n",
    "    return loss\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix and process noise\n",
    "A = [1. 0. ; 0. 1.]\n",
    "Q = [0.1 0. ; 0. 0.1]\n",
    "\n",
    "# Emission matrix and process noise\n",
    "H = [1. 0. ; 0. 1.]\n",
    "R = [0.1 0. ; 0. 0.1]\n",
    "\n",
    "# Goal prior.\n",
    "p_o_given_m = MvNormal([2.,2.],[0.01 0.0 ; 0.0 0.01])\n",
    "q_s_0 = MvNormal([1.;1.],[1.0 0. ;0. 1.0])\n",
    "p_s_0 = MvNormal([1.;1.],[1.0 0. ;0. 1.0])\n",
    "\n",
    "# Horizon\n",
    "T = 2\n",
    "\n",
    "# Action as a scalar param. Needs extension to distribution\n",
    "π_t = [[0.5,0.5] for i in 1:T]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate conditional entropy: 0.762564700688027\n",
      "Instrumental value: 2.236865289869967\n",
      "Approximate conditional entropy: 1.3686253067486325\n",
      "Instrumental value: 2.1079336385691443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.475988935875771"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_EFE(p_s_0,q_s_0,p_o_given_m,π_t,A,Q,H,R,T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
